{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f9fec62",
   "metadata": {},
   "source": [
    "# LIF Master Analysis Notebook\n",
    "## Data Cleanup + Chart Generation (Single Source of Truth)\n",
    "\n",
    "This notebook is the **single source of truth** for all LIF data analysis and visualization.\n",
    "Run all cells to:\n",
    "1. Clean and validate the dataset\n",
    "2. Generate all 24 charts in Light Mode\n",
    "3. Export rich JSON statistics\n",
    "\n",
    "**Palette:** `#F8FAFC` (Bg), `#9AA6B2` (Primary), `#EF4444` (Danger)\n",
    "\n",
    "**Data Sources:**\n",
    "- Charoenwong & Bernardi (2022) - SSRN 3944435\n",
    "- Bybit Security Report (Nov 2025)\n",
    "- Anthropic Red Team (Dec 2025)\n",
    "- Rekt.news, DeFiHackLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74311ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:03:55.148203Z",
     "iopub.status.busy": "2026-01-15T06:03:55.147922Z",
     "iopub.status.idle": "2026-01-15T06:04:06.407919Z",
     "shell.execute_reply": "2026-01-15T06:04:06.407301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: /Users/elemoghenekaro/Desktop/tasks/legitimate-intervention-framework\n",
      "Data Path: /Users/elemoghenekaro/Desktop/tasks/legitimate-intervention-framework/data/refined/lif_exploits_final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "COLORS = {\n",
    "    'background': '#F8FAFC',\n",
    "    'light_blue': '#D9EAFD',\n",
    "    'mid_blue': '#BCCCDC',\n",
    "    'dark_blue': '#9AA6B2',\n",
    "    'text': '#475569',\n",
    "    'danger': '#EF4444',\n",
    "    'warning': '#F59E0B',\n",
    "    'success': '#10B981',\n",
    "    'purple': '#8B5CF6',\n",
    "    'pink': '#EC4899',\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': COLORS['background'],\n",
    "    'axes.facecolor': COLORS['background'],\n",
    "    'axes.edgecolor': COLORS['mid_blue'],\n",
    "    'axes.labelcolor': COLORS['text'],\n",
    "    'xtick.color': COLORS['text'],\n",
    "    'ytick.color': COLORS['text'],\n",
    "    'text.color': COLORS['text'],\n",
    "    'font.family': 'sans-serif',\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.titlepad': 20,\n",
    "    'figure.dpi': 150,\n",
    "})\n",
    "\n",
    "# Dynamic Path Resolution\n",
    "def find_project_root():\n",
    "    cwd = os.getcwd()\n",
    "    # Walk up until we find legitimate-intervention-framework\n",
    "    while os.path.basename(cwd) != 'legitimate-intervention-framework' and cwd != '/':\n",
    "        cwd = os.path.dirname(cwd)\n",
    "    if cwd == '/':\n",
    "        # Fallback - assume we're in scripts/analysis\n",
    "        return os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "    return cwd\n",
    "\n",
    "BASE_DIR = find_project_root()\n",
    "DATA_PATH = os.path.join(BASE_DIR, 'data/refined/lif_exploits_final.csv')\n",
    "VIZ_PATH = os.path.join(BASE_DIR, 'visualizations')\n",
    "JSON_PATH = os.path.join(BASE_DIR, 'data/refined/lif_stats.json')\n",
    "CLEANED_CSV = os.path.join(BASE_DIR, 'data/refined/lif_exploits_cleaned.csv')\n",
    "\n",
    "os.makedirs(VIZ_PATH, exist_ok=True)\n",
    "print(f\"Project Root: {BASE_DIR}\")\n",
    "print(f\"Data Path: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfc1516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:04:06.411238Z",
     "iopub.status.busy": "2026-01-15T06:04:06.411067Z",
     "iopub.status.idle": "2026-01-15T06:04:06.420294Z",
     "shell.execute_reply": "2026-01-15T06:04:06.419403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial records: 765\n",
      "Initial total loss: $132,747,759,722\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "print(f\"Initial records: {len(df)}\")\n",
    "print(f\"Initial total loss: ${df['loss_usd'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c07369b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:04:06.421786Z",
     "iopub.status.busy": "2026-01-15T06:04:06.421682Z",
     "iopub.status.idle": "2026-01-15T06:04:06.444280Z",
     "shell.execute_reply": "2026-01-15T06:04:06.443807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA CLEANING\n",
      "============================================================\n",
      "\n",
      "[FIX 1] Found 2 Bybit records (Feb 2025) - Merging...\n",
      "  → Merged to single record: $1.5B\n",
      "\n",
      "[FIX 2] Dropping 1 duplicate Terra events\n",
      "\n",
      "[FIX 3] Vector reclassification complete\n",
      "[FIX 4] Chain reclassification complete\n",
      "[FIX 5] LIF relevance tagging: 438 relevant records\n",
      "\n",
      "✓ Cleaned data saved: /Users/elemoghenekaro/Desktop/tasks/legitimate-intervention-framework/data/refined/lif_exploits_cleaned.csv\n",
      "  Final records: 763\n",
      "  Final total loss: $91,317,759,722\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PHASE 1: DATA CLEANING\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA CLEANING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# --- FIX 1: Merge Bybit Duplicates ---\n",
    "bybit_mask = (df['protocol'].str.contains('Bybit|ByBit', case=False, na=False)) & \\\n",
    "             (df['date'] >= '2025-02-19') & (df['date'] <= '2025-02-22')\n",
    "bybit_rows = df[bybit_mask]\n",
    "if len(bybit_rows) > 1:\n",
    "    print(f\"\\n[FIX 1] Found {len(bybit_rows)} Bybit records (Feb 2025) - Merging...\")\n",
    "    max_idx = bybit_rows['loss_usd'].idxmax()\n",
    "    drop_idx = [i for i in bybit_rows.index if i != max_idx]\n",
    "    df = df.drop(drop_idx)\n",
    "    df.loc[max_idx, 'loss_usd'] = 1500000000\n",
    "    df.loc[max_idx, 'protocol'] = 'Bybit'\n",
    "    df.loc[max_idx, 'vector_category'] = 'Blind Signing / Social Engineering (Lazarus)'\n",
    "    print(\"  → Merged to single record: $1.5B\")\n",
    "\n",
    "# --- FIX 2: Deduplicate Terra/Luna ---\n",
    "terra_mask = (df['loss_usd'] >= 39_000_000_000) & (df['year'] == 2022)\n",
    "if terra_mask.sum() > 1:\n",
    "    print(f\"\\n[FIX 2] Dropping {terra_mask.sum() - 1} duplicate Terra events\")\n",
    "    df = df.drop(df[terra_mask].index[1:])\n",
    "\n",
    "# --- FIX 3: Reclassify Vectors ---\n",
    "vector_mapping = {\n",
    "    'Phishing': 'Phishing / Social Engineering',\n",
    "    'Access Control': 'Access Control / Key Compromise',\n",
    "    'Hot Wallet Access Control': 'Access Control / Key Compromise',\n",
    "    'Private Key Compromise': 'Access Control / Key Compromise',\n",
    "    'Private Key Breach': 'Access Control / Key Compromise',\n",
    "    'Logic Flaw': 'Logic Bug / Code Error',\n",
    "    'Logic Bug': 'Logic Bug / Code Error',\n",
    "    'Reentrancy': 'Logic Bug / Code Error',\n",
    "    'Reentrancy Attack': 'Logic Bug / Code Error',\n",
    "    'Precision Loss': 'Logic Bug / Code Error',\n",
    "    'Overflow': 'Logic Bug / Code Error',\n",
    "    'Unsafe Math': 'Logic Bug / Code Error',\n",
    "    'Oracle Issue': 'Oracle / Price Manipulation',\n",
    "    'Price Manipulation': 'Oracle / Price Manipulation',\n",
    "    'Faulty Oracle': 'Oracle / Price Manipulation',\n",
    "    'Flash Loan Attack': 'Flash Loan / Economic Exploit',\n",
    "    'Flashloan': 'Flash Loan / Economic Exploit',\n",
    "    'Economic Collapse': 'Economic / Systemic Failure',\n",
    "    'Economic Failure': 'Economic / Systemic Failure',\n",
    "    'CeFi Insolvency': 'Economic / Systemic Failure',\n",
    "    'Rugpull': 'Rugpull / Exit Scam',\n",
    "    'Admin Coup': 'Governance / Voting Exploit',\n",
    "}\n",
    "\n",
    "def reclassify_vector(v):\n",
    "    if pd.isna(v) or v == 'Other':\n",
    "        return 'Uncategorized'\n",
    "    for key, val in vector_mapping.items():\n",
    "        if key.lower() in v.lower():\n",
    "            return val\n",
    "    return v\n",
    "\n",
    "df['vector_category'] = df['vector_category'].apply(reclassify_vector)\n",
    "print(f\"\\n[FIX 3] Vector reclassification complete\")\n",
    "\n",
    "# --- FIX 4: Reclassify Chains ---\n",
    "protocol_chain_map = {\n",
    "    'Terra / Luna': 'Terra', 'Luna / UST': 'Terra', 'Terra Classic': 'Terra',\n",
    "    'Celsius': 'CeFi', 'Voyager': 'CeFi', 'Mt. Gox': 'CeFi', 'FTX': 'CeFi',\n",
    "    'Mixin': 'CeFi', 'DMM Bitcoin': 'CeFi', 'Bybit': 'CeFi', 'WazirX': 'CeFi',\n",
    "    'BtcTurk': 'CeFi', 'Indodax': 'CeFi', 'CoinEx': 'CeFi', 'Poloniex': 'CeFi',\n",
    "}\n",
    "chain_mapping = {'Other': 'Multi-chain / Unknown'}\n",
    "\n",
    "def reclassify_chain(row):\n",
    "    protocol = str(row['protocol']) if pd.notna(row['protocol']) else ''\n",
    "    chain = str(row['chain']) if pd.notna(row['chain']) else 'Unknown'\n",
    "    for prot, ch in protocol_chain_map.items():\n",
    "        if prot.lower() in protocol.lower():\n",
    "            return ch\n",
    "    return chain_mapping.get(chain, chain)\n",
    "\n",
    "df['chain'] = df.apply(reclassify_chain, axis=1)\n",
    "print(f\"[FIX 4] Chain reclassification complete\")\n",
    "\n",
    "# --- FIX 5: Add LIF Relevance Column ---\n",
    "lif_relevant_vectors = ['Access Control', 'Logic Bug', 'Oracle', 'Flash Loan', \n",
    "                        'Reentrancy', 'Price Manipulation', 'Governance']\n",
    "\n",
    "def is_lif_relevant(row):\n",
    "    v = str(row['vector_category']).lower()\n",
    "    return any(term.lower() in v for term in lif_relevant_vectors)\n",
    "\n",
    "df['is_lif_relevant'] = df.apply(is_lif_relevant, axis=1)\n",
    "print(f\"[FIX 5] LIF relevance tagging: {df['is_lif_relevant'].sum()} relevant records\")\n",
    "\n",
    "# Standardize protocol names\n",
    "df['protocol'] = df['protocol'].replace({\n",
    "    'ByBit': 'Bybit', 'Terra Classic': 'Terra / Luna', 'Luna / UST': 'Terra / Luna'\n",
    "})\n",
    "\n",
    "# Save cleaned CSV\n",
    "df.to_csv(CLEANED_CSV, index=False)\n",
    "print(f\"\\n✓ Cleaned data saved: {CLEANED_CSV}\")\n",
    "print(f\"  Final records: {len(df)}\")\n",
    "print(f\"  Final total loss: ${df['loss_usd'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3baf39af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:04:06.445408Z",
     "iopub.status.busy": "2026-01-15T06:04:06.445328Z",
     "iopub.status.idle": "2026-01-15T06:04:06.448339Z",
     "shell.execute_reply": "2026-01-15T06:04:06.447929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ External data loaded with sources\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EXTERNAL DATA SOURCES (with citations)\n",
    "# ============================================================\n",
    "\n",
    "# Charoenwong & Bernardi (2022), SSRN 3944435, Table 2\n",
    "CHAROENWONG_DATA = {\n",
    "    'hack_types': {'Security Breach': 20, 'Human Error': 5, 'Agency Problem': 5},\n",
    "    'total_incidents': 30, 'date_range': '2011-2021',\n",
    "    'source': 'Charoenwong & Bernardi (2022), SSRN 3944435'\n",
    "}\n",
    "\n",
    "# Bybit Security Report (Nov 2025)\n",
    "BYBIT_DATA = {\n",
    "    'freezing_capability': {'No Freezing': 131, 'Confirmed Freezing': 16, 'Potential Freezing': 19},\n",
    "    'total_chains': 166,\n",
    "    'freezing_methods': {\n",
    "        'Hardcoded': ['BNB', 'VeChain', 'Chiliz', 'VIC', 'XDC'],\n",
    "        'Config File': ['Sui', 'Aptos', 'Harmony', 'Linea', 'Waves', 'EOS', 'Oasis'],\n",
    "        'Smart Contract': ['HECO'],\n",
    "    },\n",
    "    'source': 'Bybit Security Research, Nov 2025'\n",
    "}\n",
    "\n",
    "# Anthropic Red Team Report (Dec 2025)\n",
    "ANTHROPIC_DATA = {\n",
    "    'ai_exploit_revenue': {\n",
    "        'dates': ['2025-01', '2025-03', '2025-05', '2025-07', '2025-09', '2025-11', '2025-12'],\n",
    "        'revenue_millions': [0.005, 0.02, 0.08, 0.32, 1.28, 3.5, 4.6],\n",
    "    },\n",
    "    'doubling_rate_months': 1.3, 'cost_per_scan_usd': 1.22,\n",
    "    'contracts_scanned': 2849, 'zero_days_found': 2,\n",
    "    'source': 'Anthropic Red Team, Dec 2025'\n",
    "}\n",
    "\n",
    "# Recovery rates from case studies\n",
    "RECOVERY_DATA = {\n",
    "    'by_time': {\n",
    "        'Minutes': {'rate': 95, 'examples': ['HECO freeze']},\n",
    "        'Hours': {'rate': 60, 'examples': ['Sui freeze']},\n",
    "        'Days': {'rate': 30, 'examples': ['BNB recovery']},\n",
    "        'Weeks': {'rate': 5, 'examples': ['Most exploits']},\n",
    "    },\n",
    "    'source': 'LIF Case Studies Analysis'\n",
    "}\n",
    "\n",
    "print(\"✓ External data loaded with sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a1e51d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:04:06.449485Z",
     "iopub.status.busy": "2026-01-15T06:04:06.449410Z",
     "iopub.status.idle": "2026-01-15T06:04:07.183812Z",
     "shell.execute_reply": "2026-01-15T06:04:07.183348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GENERATING CHARTS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] C01: Hack Type Distribution\n",
      "  [2] C03: Code is Law Breakdown\n",
      "  [3] C04: Freezing Methodology\n",
      "  [4] C05: Recovery vs Speed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [5] C06: AI Acceleration\n",
      "  [6] C07: AI Token Cost\n",
      "  [7] C08: AI Cost Metric\n",
      "\n",
      "  Part 1 complete: 7 charts\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CHART GENERATION - Part 1: External Data Charts\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING CHARTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "chart_count = 0\n",
    "\n",
    "# C01: Hack Type Distribution (Charoenwong)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "data = CHAROENWONG_DATA['hack_types']\n",
    "colors = [COLORS['danger'], COLORS['warning'], COLORS['dark_blue']]\n",
    "ax.pie(data.values(), labels=data.keys(), autopct='%1.0f%%', colors=colors, startangle=90)\n",
    "ax.set_title('Hack Type Distribution (2011-2021)\\nSource: Charoenwong & Bernardi')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c01_hack_type_distribution.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C01: Hack Type Distribution\")\n",
    "\n",
    "# C03: Code is Law Breakdown (Bybit)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "data = BYBIT_DATA['freezing_capability']\n",
    "colors = [COLORS['mid_blue'], COLORS['danger'], COLORS['warning']]\n",
    "ax.pie(data.values(), labels=data.keys(), autopct='%1.1f%%', colors=colors, startangle=90, explode=(0, 0.05, 0.02))\n",
    "ax.set_title('Blockchain Freezing Capability\\nSource: Bybit (166 chains)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c03_code_is_law_breakdown.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C03: Code is Law Breakdown\")\n",
    "\n",
    "# C04: Freezing Methodology\n",
    "methods = ['Hardcoded', 'Config File', 'Smart Contract']\n",
    "transparency, speed, flexibility = [90, 30, 80], [20, 50, 95], [10, 40, 90]\n",
    "x = np.arange(len(methods))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(x - width, transparency, width, label='Transparency', color=COLORS['light_blue'])\n",
    "ax.bar(x, speed, width, label='Speed', color=COLORS['dark_blue'])\n",
    "ax.bar(x + width, flexibility, width, label='Flexibility', color=COLORS['danger'])\n",
    "ax.set_ylabel('Score (0-100)')\n",
    "ax.set_title('Freezing Methodology Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend()\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c04_freezing_methodology.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C04: Freezing Methodology\")\n",
    "\n",
    "# C05: Recovery vs Speed\n",
    "times = list(RECOVERY_DATA['by_time'].keys())\n",
    "rates = [v['rate'] for v in RECOVERY_DATA['by_time'].values()]\n",
    "colors_bars = [COLORS['success'], COLORS['light_blue'], COLORS['warning'], COLORS['danger']]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "bars = ax.bar(times, rates, color=colors_bars)\n",
    "ax.bar_label(bars, fmt='%d%%', padding=3)\n",
    "ax.set_ylabel('Recovery Rate (%)')\n",
    "ax.set_xlabel('Intervention Speed')\n",
    "ax.set_title('Recovery Rate vs Intervention Speed')\n",
    "ax.set_ylim(0, 110)\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c05_recovery_vs_speed.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C05: Recovery vs Speed\")\n",
    "\n",
    "# C06: AI Acceleration\n",
    "dates = ['Jan', 'Mar', 'May', 'Jul', 'Sep', 'Nov', 'Dec']\n",
    "revenue = ANTHROPIC_DATA['ai_exploit_revenue']['revenue_millions']\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(dates, revenue, marker='o', color=COLORS['danger'], linewidth=3, markersize=8)\n",
    "ax.fill_between(dates, revenue, color=COLORS['danger'], alpha=0.1)\n",
    "ax.set_yscale('log')\n",
    "ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: f'${y:.2f}M' if y < 1 else f'${y:.1f}M'))\n",
    "ax.set_title(f'AI Exploit Revenue Acceleration (2025)\\nDoubling every {ANTHROPIC_DATA[\"doubling_rate_months\"]} months')\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c06_ai_exploit_acceleration.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C06: AI Acceleration\")\n",
    "\n",
    "# C07: AI Token Cost\n",
    "models = ['Opus 4.0\\n(Jun)', 'Sonnet 4.0\\n(Aug)', 'Opus 4.5\\n(Oct)', 'Current\\n(Dec)']\n",
    "costs = [100, 77, 50, 29.8]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "bars = ax.bar(models, costs, color=[COLORS['dark_blue'], COLORS['mid_blue'], COLORS['light_blue'], COLORS['success']])\n",
    "ax.bar_label(bars, fmt='%.1f%%', padding=3)\n",
    "ax.set_ylabel('Relative Token Cost (%)')\n",
    "ax.set_title('AI Token Cost Reduction (70.2% in 6 months)')\n",
    "ax.axhline(100, color=COLORS['danger'], linestyle='--', alpha=0.3)\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c07_ai_token_cost.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C07: AI Token Cost\")\n",
    "\n",
    "# C08: AI Cost Metric\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.text(0.5, 0.6, f'${ANTHROPIC_DATA[\"cost_per_scan_usd\"]:.2f}', fontsize=48, fontweight='bold', ha='center', va='center', color=COLORS['dark_blue'])\n",
    "ax.text(0.5, 0.35, 'Average Cost per Contract Scan', fontsize=14, ha='center', va='center', color=COLORS['text'])\n",
    "ax.text(0.5, 0.2, f'{ANTHROPIC_DATA[\"contracts_scanned\"]:,} contracts | {ANTHROPIC_DATA[\"zero_days_found\"]} zero-days found', fontsize=10, ha='center', va='center', color=COLORS['mid_blue'])\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c08_ai_cost_metric.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C08: AI Cost Metric\")\n",
    "\n",
    "print(f\"\\n  Part 1 complete: {chart_count} charts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11bff459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:04:07.185080Z",
     "iopub.status.busy": "2026-01-15T06:04:07.185003Z",
     "iopub.status.idle": "2026-01-15T06:04:07.561888Z",
     "shell.execute_reply": "2026-01-15T06:04:07.561390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [8] C09: Freeze Timeline\n",
      "  [9] C10: Architectures of Control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [10] C13: Regulatory Models\n",
      "  [11] C15: Sovereignty Spectrum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [12] C22: LIF Stack\n",
      "  [13] C25: ZKP Flow\n",
      "  [14] C26: Optimistic Freeze\n",
      "\n",
      "  Part 2 complete: 14 charts total\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CHART GENERATION - Part 2: Conceptual Diagrams\n",
    "# ============================================================\n",
    "\n",
    "# C09: Freeze Timeline\n",
    "events = [('07:46', 'Balancer exploit', '$121M'), ('07:52', 'Hypernative flagged', ''),\n",
    "          ('08:07', 'V6 pools paused', '$19.3M saved'), ('08:14', 'SEAL 911 contacted', ''),\n",
    "          ('11:01', 'Recovery Mode', ''), ('Next Day', 'Moonwell exploit', '$1M')]\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "y_pos = 0.5\n",
    "for i, (time, event, amount) in enumerate(events):\n",
    "    x = i / (len(events) - 1)\n",
    "    color = COLORS['danger'] if 'exploit' in event.lower() else COLORS['success']\n",
    "    ax.scatter(x, y_pos, s=200, c=color, zorder=5)\n",
    "    ax.annotate(f'{time}\\n{event}\\n{amount}', (x, y_pos + 0.1), ha='center', va='bottom', fontsize=9,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor=COLORS['light_blue'], alpha=0.5))\n",
    "ax.axhline(y_pos, color=COLORS['mid_blue'], linewidth=2, zorder=1)\n",
    "ax.set_xlim(-0.1, 1.1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('Freeze First Timeline: Nov 3-4, 2025 (Balancer & Moonwell)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c09_freeze_timeline.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C09: Freeze Timeline\")\n",
    "\n",
    "# C10: 4 Architectures of Control\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "architectures = [('HARDCODED', 'Protocol Layer', 'Requires Hard Fork', COLORS['danger']),\n",
    "                 ('CONFIG-BASED', 'Validator Config', 'Node Restart', COLORS['warning']),\n",
    "                 ('SMART CONTRACT', 'Admin Contract', 'On-chain Tx', COLORS['success']),\n",
    "                 ('REACTIVE', 'GitHub Commit', 'Chain Upgrade', COLORS['purple'])]\n",
    "for i, (name, layer, action, color) in enumerate(architectures):\n",
    "    y = 0.8 - i * 0.2\n",
    "    ax.add_patch(mpatches.FancyBboxPatch((0.05, y - 0.08), 0.25, 0.14, boxstyle=\"round,pad=0.02\", facecolor=color, alpha=0.3))\n",
    "    ax.add_patch(mpatches.FancyBboxPatch((0.35, y - 0.08), 0.25, 0.14, boxstyle=\"round,pad=0.02\", facecolor=color, alpha=0.5))\n",
    "    ax.add_patch(mpatches.FancyBboxPatch((0.65, y - 0.08), 0.3, 0.14, boxstyle=\"round,pad=0.02\", facecolor=color, alpha=0.7))\n",
    "    ax.text(0.175, y, name, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "    ax.text(0.475, y, layer, ha='center', va='center', fontsize=10)\n",
    "    ax.text(0.8, y, action, ha='center', va='center', fontsize=10)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('4 Architectures of Control')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c10_architectures_control.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C10: Architectures of Control\")\n",
    "\n",
    "# C13: 5 Regulatory Models (Table)\n",
    "models_data = {\n",
    "    'Model': ['Centralized', 'Gatekeeper', 'RegTech', 'Ex Ante Auto', 'Ex Post DeFi'],\n",
    "    'Fixed Cost': ['Moderate', 'Moderate', 'High', 'Very High', 'Very High'],\n",
    "    'Variable Cost': ['High', 'Moderate', 'Low', 'Very Low', 'High'],\n",
    "    'Timing': ['Ex Post', 'Mixed', 'Real-time', 'Preventive', 'Ex Post'],\n",
    "    'Authority': ['Human', 'Human', 'Algo+Human', 'Algorithmic', 'Human'],\n",
    "}\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=[models_data['Fixed Cost'], models_data['Variable Cost'], models_data['Timing'], models_data['Authority']],\n",
    "                 rowLabels=['Fixed Cost', 'Variable Cost', 'Timing', 'Authority'],\n",
    "                 colLabels=models_data['Model'], loc='center', cellLoc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1.2, 1.8)\n",
    "ax.set_title('5 Regulatory Models Comparison', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c13_regulatory_models.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C13: Regulatory Models\")\n",
    "\n",
    "# C15: Sovereignty Spectrum\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
    "ax.imshow(gradient, aspect='auto', cmap='RdYlGn_r', extent=[0, 10, 0, 1])\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(-0.5, 1.5)\n",
    "for x in [2, 5, 8]: ax.axvline(x, color='white', linewidth=2, linestyle='--')\n",
    "labels = [(1, '\"Code is Law\"\\nNo Intervention'), (3.5, 'Minimal\\nGovernance'), (6.5, 'Optimistic\\nFreeze'), (9, '\"Law as Code\"\\nFull Compliance')]\n",
    "for x, label in labels:\n",
    "    ax.text(x, 1.2, label, ha='center', va='bottom', fontsize=10)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "ax.set_title('Sovereignty Risk Spectrum')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c15_sovereignty_spectrum.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C15: Sovereignty Spectrum\")\n",
    "\n",
    "# C22: LIF Stack\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "layers = [('L3: Legal Layer', 'DUNA/LLC Entity', COLORS['purple'], 0.85),\n",
    "          ('L2: Safety Layer', 'Optimistic Freeze + Insurance', COLORS['success'], 0.65),\n",
    "          ('L1: Consensus Layer', 'Base Protocol', COLORS['dark_blue'], 0.45),\n",
    "          ('L0: Infrastructure', 'Nodes, Validators, RPC', COLORS['mid_blue'], 0.25)]\n",
    "for name, desc, color, y in layers:\n",
    "    ax.add_patch(mpatches.FancyBboxPatch((0.1, y - 0.08), 0.8, 0.15, boxstyle=\"round,pad=0.02\", facecolor=color, alpha=0.7))\n",
    "    ax.text(0.5, y, f'{name}\\n{desc}', ha='center', va='center', fontsize=11, fontweight='bold', color='white')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('Complete LIF Stack')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c22_lif_stack.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C22: LIF Stack\")\n",
    "\n",
    "# C25: ZKP Flow\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "steps = [('Prover', 'Generates proof', COLORS['dark_blue']), ('Proof', 'ZK-SNARK', COLORS['success']),\n",
    "         ('Verifier', 'On-chain contract', COLORS['purple']), ('Result', 'Allow/Block', COLORS['danger'])]\n",
    "for i, (name, desc, color) in enumerate(steps):\n",
    "    x = i / (len(steps) - 1) * 0.8 + 0.1\n",
    "    ax.add_patch(mpatches.Circle((x, 0.5), 0.08, facecolor=color, alpha=0.7))\n",
    "    ax.text(x, 0.5, name, ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n",
    "    ax.text(x, 0.25, desc, ha='center', va='top', fontsize=9)\n",
    "    if i < len(steps) - 1:\n",
    "        ax.annotate('→', ((x + (i+1)/(len(steps)-1)*0.8+0.1)/2, 0.5), fontsize=20, ha='center')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('ZKP Compliance Architecture')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c25_zkp_flow.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C25: ZKP Flow\")\n",
    "\n",
    "# C26: Optimistic Freeze\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "steps = [('Trigger', 'Anomaly\\nDetected', COLORS['warning']), ('Pause', 'Immediate\\nFreeze', COLORS['danger']),\n",
    "         ('Vote', 'DAO/Council\\nVote', COLORS['purple']), ('Outcome', 'Confirm or\\nSlash Bond', COLORS['success'])]\n",
    "for i, (name, desc, color) in enumerate(steps):\n",
    "    x = i / (len(steps) - 1) * 0.8 + 0.1\n",
    "    ax.add_patch(mpatches.FancyBboxPatch((x - 0.08, 0.35), 0.16, 0.3, boxstyle=\"round,pad=0.02\", facecolor=color, alpha=0.7))\n",
    "    ax.text(x, 0.5, f'{name}\\n{desc}', ha='center', va='center', fontsize=9, fontweight='bold', color='white')\n",
    "    if i < len(steps) - 1:\n",
    "        ax.annotate('→', ((x + (i+1)/(len(steps)-1)*0.8+0.1)/2, 0.5), fontsize=20, ha='center', color=COLORS['text'])\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('Optimistic Freeze Mechanism')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c26_optimistic_freeze.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C26: Optimistic Freeze\")\n",
    "\n",
    "print(f\"\\n  Part 2 complete: {chart_count} charts total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "698c74d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:04:07.563114Z",
     "iopub.status.busy": "2026-01-15T06:04:07.563028Z",
     "iopub.status.idle": "2026-01-15T06:04:08.547093Z",
     "shell.execute_reply": "2026-01-15T06:04:08.546731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [15] C02: Cumulative Losses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [16] C17: Top 10 Exploits\n",
      "  [17] C18: Vector Distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [18] C19: Chain Distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [19] C20: Losses by Year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [20] A01: Exploit Scatter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [21] A02: Pareto Analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [22] A03: Heatmap\n",
      "  [23] Monthly Trends 2024-2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [24] LIF Addressable\n",
      "\n",
      "✓ Total charts generated: 24\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CHART GENERATION - Part 3: Data-Driven Charts\n",
    "# ============================================================\n",
    "\n",
    "# C02: Cumulative Losses\n",
    "yearly_cum = df.groupby('year')['loss_usd'].sum().cumsum() / 1_000_000_000\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.fill_between(yearly_cum.index, yearly_cum.values, color=COLORS['danger'], alpha=0.3)\n",
    "ax.plot(yearly_cum.index, yearly_cum.values, color=COLORS['danger'], linewidth=3, marker='o')\n",
    "ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('$%.0fB'))\n",
    "ax.set_title('Cumulative Crypto Exploit Losses')\n",
    "ax.set_ylabel('Cumulative Loss (Billions USD)')\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c02_cumulative_losses.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C02: Cumulative Losses\")\n",
    "\n",
    "# C17: Top 10 Exploits\n",
    "top10 = df.nlargest(10, 'loss_usd')[['protocol', 'loss_usd']].copy()\n",
    "top10['loss_billions'] = top10['loss_usd'] / 1_000_000_000\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(top10['protocol'], top10['loss_billions'], color=COLORS['dark_blue'])\n",
    "bars[0].set_color(COLORS['danger'])\n",
    "ax.bar_label(bars, fmt=' $%.2fB', padding=3, color=COLORS['text'])\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Top 10 Largest Crypto Exploits (2014-2025)')\n",
    "ax.set_xlabel('Loss (Billions USD)')\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c17_top10_exploits.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C17: Top 10 Exploits\")\n",
    "\n",
    "# C18: Vector Distribution\n",
    "vectors = df['vector_category'].value_counts().head(10)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "colors_pie = [COLORS['dark_blue'], COLORS['danger'], COLORS['mid_blue'], COLORS['warning'], \n",
    "              COLORS['success'], COLORS['light_blue'], COLORS['purple'], COLORS['pink']] * 2\n",
    "ax.pie(vectors, labels=vectors.index, autopct='%1.1f%%', colors=colors_pie[:len(vectors)], startangle=90, textprops={'fontsize': 9})\n",
    "ax.set_title('Attack Vector Distribution (Top 10)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c18_vector_distribution.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C18: Vector Distribution\")\n",
    "\n",
    "# C19: Chain Distribution\n",
    "chains = df.groupby('chain')['loss_usd'].sum().sort_values(ascending=False).head(10) / 1_000_000_000\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(chains.index, chains.values, color=COLORS['mid_blue'])\n",
    "ax.bar_label(bars, fmt='$%.1fB', padding=3, fontsize=8)\n",
    "ax.set_title('Losses by Chain (Top 10)')\n",
    "ax.set_ylabel('Loss (Billions USD)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c19_chain_distribution.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C19: Chain Distribution\")\n",
    "\n",
    "# C20: Losses by Year\n",
    "yearly_sum = df.groupby('year')['loss_usd'].sum() / 1_000_000_000\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.fill_between(yearly_sum.index, yearly_sum.values, color=COLORS['light_blue'], alpha=0.5)\n",
    "ax.plot(yearly_sum.index, yearly_sum.values, color=COLORS['dark_blue'], linewidth=2, marker='o')\n",
    "ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('$%.0fB'))\n",
    "ax.set_title('Annual Crypto Exploit Losses')\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'c20_losses_by_year.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] C20: Losses by Year\")\n",
    "\n",
    "# A01: Scatter Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sizes = np.clip(df['loss_usd'] / 1_000_000 * 2, 10, 500)\n",
    "ax.scatter(df['date'], df['loss_usd'], s=sizes, color=COLORS['dark_blue'], alpha=0.5, edgecolors='white', linewidth=0.5)\n",
    "ax.set_yscale('log')\n",
    "ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: '${:,.0f}'.format(y)))\n",
    "ax.set_title('Timeline of Individual Exploits (Log Scale)')\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'a01_exploit_scatter.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] A01: Exploit Scatter\")\n",
    "\n",
    "# A02: Pareto\n",
    "sorted_df = df.sort_values(by='loss_usd', ascending=False).reset_index(drop=True)\n",
    "sorted_df['cumulative_pct'] = 100 * sorted_df['loss_usd'].cumsum() / df['loss_usd'].sum()\n",
    "sorted_df['protocol_pct'] = 100 * (sorted_df.index + 1) / len(sorted_df)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(sorted_df['protocol_pct'], sorted_df['cumulative_pct'], color=COLORS['dark_blue'], linewidth=2)\n",
    "ax.axhline(80, color=COLORS['danger'], linestyle='--', alpha=0.5)\n",
    "x_80 = sorted_df[sorted_df['cumulative_pct'] >= 80]['protocol_pct'].iloc[0]\n",
    "ax.axvline(x_80, color=COLORS['danger'], linestyle='--', alpha=0.5)\n",
    "ax.fill_between(sorted_df[sorted_df['protocol_pct'] <= x_80]['protocol_pct'], \n",
    "                sorted_df[sorted_df['protocol_pct'] <= x_80]['cumulative_pct'], alpha=0.3, color=COLORS['danger'])\n",
    "ax.text(x_80 + 2, 10, f'Top {x_80:.1f}% = 80% Loss', color=COLORS['text'], fontsize=11)\n",
    "ax.set_title('Pareto Analysis: Concentration of Losses')\n",
    "ax.set_xlabel('% of Protocols')\n",
    "ax.set_ylabel('Cumulative % of Loss')\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'a02_pareto.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] A02: Pareto Analysis\")\n",
    "\n",
    "# A03: Heatmap\n",
    "pivot = df.pivot_table(index='month', columns='year', values='loss_usd', aggfunc='count', fill_value=0)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.heatmap(pivot, cmap='Blues', linewidths=.5, ax=ax, cbar_kws={'label': 'Exploit Count'})\n",
    "ax.set_title('Exploit Frequency Heatmap')\n",
    "ax.set_yticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'a03_heatmap.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] A03: Heatmap\")\n",
    "\n",
    "# Monthly Trends 2024-2025\n",
    "recent = df[df['year'] >= 2024].copy()\n",
    "if not recent.empty:\n",
    "    recent['year_month'] = recent['date'].dt.to_period('M')\n",
    "    monthly = recent.groupby('year_month')['loss_usd'].sum() / 1_000_000\n",
    "    monthly.index = monthly.index.astype(str)\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.fill_between(monthly.index, monthly.values, color=COLORS['danger'], alpha=0.3)\n",
    "    ax.plot(monthly.index, monthly.values, color=COLORS['danger'], marker='o')\n",
    "    ax.set_title('Monthly Loss Trends (2024-2025)')\n",
    "    ax.set_ylabel('Loss (Millions USD)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(VIZ_PATH, 'monthly_trends_2024_2025.png'))\n",
    "    plt.close()\n",
    "    chart_count += 1\n",
    "    print(f\"  [{chart_count}] Monthly Trends 2024-2025\")\n",
    "\n",
    "# LIF Addressable\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "lif_losses = df[df['is_lif_relevant']]['loss_usd'].sum() / 1_000_000_000\n",
    "other_losses = df[~df['is_lif_relevant']]['loss_usd'].sum() / 1_000_000_000\n",
    "bars = ax.bar(['LIF-Addressable\\nExploits', 'Other Exploits'], [lif_losses, other_losses], \n",
    "              color=[COLORS['success'], COLORS['mid_blue']])\n",
    "ax.bar_label(bars, fmt='$%.1fB', padding=3)\n",
    "ax.set_ylabel('Total Loss (Billions USD)')\n",
    "ax.set_title('LIF-Addressable vs Other Exploits')\n",
    "for s in ['top', 'right']: ax.spines[s].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(VIZ_PATH, 'lif_addressable.png'))\n",
    "plt.close()\n",
    "chart_count += 1\n",
    "print(f\"  [{chart_count}] LIF Addressable\")\n",
    "\n",
    "print(f\"\\n✓ Total charts generated: {chart_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82959ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:04:08.548422Z",
     "iopub.status.busy": "2026-01-15T06:04:08.548344Z",
     "iopub.status.idle": "2026-01-15T06:04:08.557609Z",
     "shell.execute_reply": "2026-01-15T06:04:08.557215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPORTING JSON STATISTICS\n",
      "============================================================\n",
      "✓ JSON stats saved: /Users/elemoghenekaro/Desktop/tasks/legitimate-intervention-framework/data/refined/lif_stats.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EXPORT RICH JSON STATISTICS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPORTING JSON STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def sanitize_for_json(obj):\n",
    "    if hasattr(obj, 'isoformat'): return obj.isoformat()\n",
    "    if hasattr(obj, 'item'): return obj.item()  # numpy types\n",
    "    return str(obj)\n",
    "\n",
    "def sanitize_dict(d):\n",
    "    return {str(k): sanitize_for_json(v) if not isinstance(v, dict) else sanitize_dict(v) for k, v in d.items()}\n",
    "\n",
    "lif_relevant_exploits = int(df['is_lif_relevant'].sum())\n",
    "lif_relevant_loss_usd = float(df[df['is_lif_relevant']]['loss_usd'].sum())\n",
    "\n",
    "stats = {\n",
    "    'summary': {\n",
    "        'total_exploits': int(len(df)),\n",
    "        'total_loss_usd': float(df['loss_usd'].sum()),\n",
    "        'lif_relevant_exploits': lif_relevant_exploits,\n",
    "        'lif_relevant_loss_usd': lif_relevant_loss_usd,\n",
    "        'top_protocol': df.nlargest(1, 'loss_usd')['protocol'].iloc[0],\n",
    "        'date_range': {'start': str(df['date'].min().date()), 'end': str(df['date'].max().date())},\n",
    "        'generated_at': datetime.now().isoformat(),\n",
    "    },\n",
    "    'top_10_exploits': [],\n",
    "    'yearly_losses': sanitize_dict(df.groupby('year')['loss_usd'].sum().to_dict()),\n",
    "    'cumulative_losses': sanitize_dict(df.groupby('year')['loss_usd'].sum().cumsum().to_dict()),\n",
    "    'vector_distribution': df['vector_category'].value_counts().head(15).to_dict(),\n",
    "    'chain_distribution': sanitize_dict(df.groupby('chain')['loss_usd'].sum().sort_values(ascending=False).head(10).to_dict()),\n",
    "    'external_data': {\n",
    "        'charoenwong': CHAROENWONG_DATA,\n",
    "        'bybit': BYBIT_DATA,\n",
    "        'anthropic': ANTHROPIC_DATA,\n",
    "        'recovery': RECOVERY_DATA,\n",
    "    },\n",
    "    'data_sources': ['charoenwong_bernardi_table.txt', 'rekt_database_raw.txt',\n",
    "                     'rekt_news_extra.txt', 'defihacklabs_incidents.json'],\n",
    "}\n",
    "\n",
    "# Top 10 exploits\n",
    "for _, row in df.nlargest(10, 'loss_usd').iterrows():\n",
    "    stats['top_10_exploits'].append({\n",
    "        'protocol': row['protocol'],\n",
    "        'loss_usd': float(row['loss_usd']),\n",
    "        'date': row['date'].isoformat() if pd.notna(row['date']) else None,\n",
    "        'vector_category': row['vector_category'],\n",
    "        'chain': row['chain'],\n",
    "        'is_lif_relevant': bool(row['is_lif_relevant']),\n",
    "    })\n",
    "\n",
    "# Monthly trends\n",
    "if not recent.empty:\n",
    "    stats['monthly_trends_2024_2025'] = sanitize_dict(\n",
    "        recent.groupby(recent['date'].dt.to_period('M'))['loss_usd'].sum().to_dict()\n",
    "    )\n",
    "\n",
    "with open(JSON_PATH, 'w') as f:\n",
    "    json.dump(stats, f, indent=2, default=str)\n",
    "\n",
    "print(f\"✓ JSON stats saved: {JSON_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calibration_metrics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:04:08.558898Z",
     "iopub.status.busy": "2026-01-15T06:04:08.558818Z",
     "iopub.status.idle": "2026-01-15T06:04:08.560837Z",
     "shell.execute_reply": "2026-01-15T06:04:08.560428Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PART 4: ELEM NIMROD PAPER CALIBRATION METRICS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CALIBRATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "METRICS_PATH = os.path.join(BASE_DIR, 'data/refined/lif_intervention_metrics.csv')\n",
    "if os.path.exists(METRICS_PATH):\n",
    "    metrics_df = pd.read_csv(METRICS_PATH)\n",
    "    print(f\"Loaded calibration metrics: {len(metrics_df)} incidents\")\n",
    "\n",
    "    # C27: Time to Containment vs Loss Prevented\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    # Filter for incidents with valid time and prevention data\n",
    "    plot_df = metrics_df[metrics_df['time_to_contain_min'] > 0].copy()\n",
    "    \n",
    "    sc = ax.scatter(plot_df['time_to_contain_min'], \n",
    "                   plot_df['loss_prevented_usd'] / 1e6, \n",
    "                   s=plot_df['containment_success_pct']*3, \n",
    "                   c=COLORS['dark_blue'], alpha=0.7)\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Time to Containment (Minutes)')\n",
    "    ax.set_ylabel('Loss Prevented ($M)')\n",
    "    ax.set_title('Intervention Efficacy: Speed vs Value Preserved')\n",
    "    \n",
    "    # Annotate points\n",
    "    for _, row in plot_df.iterrows():\n",
    "        ax.annotate(row['protocol'], \n",
    "                   (row['time_to_contain_min'], row['loss_prevented_usd']/1e6), \n",
    "                   fontsize=8, xytext=(5, 5), textcoords='offset points')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(VIZ_PATH, 'c27_intervention_efficacy.png'))\n",
    "    plt.close()\n",
    "    print(\"  [25] C27: Intervention Efficacy\")\n",
    "    chart_count += 1\n",
    "else:\n",
    "    print(f\"Warning: {METRICS_PATH} not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22ea6415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:04:08.561852Z",
     "iopub.status.busy": "2026-01-15T06:04:08.561775Z",
     "iopub.status.idle": "2026-01-15T06:04:08.564756Z",
     "shell.execute_reply": "2026-01-15T06:04:08.564319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPLETE!\n",
      "============================================================\n",
      "  Records cleaned: 763\n",
      "  Total loss: $91,317,759,722\n",
      "  Charts generated: 24\n",
      "  LIF-relevant: 438 exploits ($10,759,673,502)\n",
      "\n",
      "Files created:\n",
      "  - /Users/elemoghenekaro/Desktop/tasks/legitimate-intervention-framework/data/refined/lif_exploits_cleaned.csv\n",
      "  - /Users/elemoghenekaro/Desktop/tasks/legitimate-intervention-framework/data/refined/lif_stats.json\n",
      "  - 24 PNG files in /Users/elemoghenekaro/Desktop/tasks/legitimate-intervention-framework/visualizations\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Records cleaned: {len(df)}\")\n",
    "print(f\"  Total loss: ${df['loss_usd'].sum():,.0f}\")\n",
    "print(f\"  Charts generated: {chart_count}\")\n",
    "print(f\"  LIF-relevant: {df['is_lif_relevant'].sum()} exploits (${df[df['is_lif_relevant']]['loss_usd'].sum():,.0f})\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  - {CLEANED_CSV}\")\n",
    "print(f\"  - {JSON_PATH}\")\n",
    "print(f\"  - {chart_count} PNG files in {VIZ_PATH}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
